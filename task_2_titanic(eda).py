# -*- coding: utf-8 -*-
"""Task 2-Titanic(EDA)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/task-2-titanic-eda-6ff926a0-fc67-4570-ac3e-b3c1ab4b8919.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240522/auto/storage/goog4_request%26X-Goog-Date%3D20240522T092754Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1865e7b417010a47a99b7fb5908e4db5488d8b650752ed869bb0a68d7de347f166714cbe3d934d7f013699bf1e37b240689be98d0b02b9c8c66edf1f31974aa08bf9ae64fd3399ba33a37e9f49f173e36e3ca416eeaaa3f278c1c82a235bcafb6b453d3f66c446c078e46d9992b39f12319c486c5545dd40ad4a42f7d361f0d29054b414f49a3276734560a30cd6bc204105588c42afba194408788fe93d7a90bb709f29d7c88a8ba5c83bdf60ee63f35dd43a1b77e31c4d7015253067d208ecff6bb2a9b847893e6d0ae2d9d3009afbf19b64b535543d1e9601f710792ceb88e60ad9b04d9affa886c928b37cc8e00b5b7eae7759b44b66691f30ee2d194b79
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'titanic:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F3136%2F26502%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240522%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240522T092754Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D9dc1f8bae86a74d2f510ae5f4d6ead6d250a33d95845539a49c1a941fd6e0c51bfea21e41febd01ec6c40822e3c9aa050bf441777a3ad9d8044677f161bcdb14e772fd3ce3c52e93fb4f8b55aead1db071eac75ab0c434f6c9559b0322ef26420882836a616e63bbb9531d07a5d4547bc260654d30081cf54be38ee4f44bdef95358e89c79699edf1721e36dc6285a391a0af30a17fafcfdd62ab4c3899e6d93e09ca7a82991053385fe9f2722a24dea8066d82a6a992099a74bc0c8f314088171f87e67c3581be0c1eb83116bf84ae1c65eeef677210cc4efdcfca311a4a40fa50e5826f4675431ae600ebf9ab2b2635b18f0bdc7ad19b4967148d0c84a95e2'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the train and test datasets
train_df = pd.read_csv("/kaggle/input/titanic/train.csv")
test_df = pd.read_csv("/kaggle/input/titanic/train.csv")


# Display the first few rows of the train dataset
print("Train dataset:")
print(train_df.head())

# Display the first few rows of the test dataset
print("\nTest dataset:")
print(test_df.head())

# Data Cleaning for train dataset
# Check for missing values in the train dataset
print("\nMissing values in train dataset:")
print(train_df.isnull().sum())

# Drop irrelevant columns in the train dataset
train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)

# Fill missing values in 'Age' with the median age
train_df['Age'].fillna(train_df['Age'].median(), inplace=True)

# Fill missing values in 'Embarked' with the mode
train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)

# Convert 'Sex' and 'Embarked' to categorical variables in the train dataset
train_df['Sex'] = train_df['Sex'].astype('category')
train_df['Embarked'] = train_df['Embarked'].astype('category')

# Data Cleaning for test dataset
# Check for missing values in the test dataset
print("\nMissing values in test dataset:")
print(test_df.isnull().sum())

# Drop irrelevant columns in the test dataset
test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)

# Fill missing values in 'Age' with the median age in the test dataset
test_df['Age'].fillna(test_df['Age'].median(), inplace=True)

# Fill missing values in 'Fare' with the median fare in the test dataset
test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)

# Convert 'Sex' and 'Embarked' to categorical variables in the test dataset
test_df['Sex'] = test_df['Sex'].astype('category')
test_df['Embarked'] = test_df['Embarked'].astype('category')

# Exploratory Data Analysis (EDA) for train dataset
# Summary statistics for train dataset
print("\nSummary statistics for train dataset:")
print(train_df.describe())

# Visualize the distribution of categorical variables in train dataset
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.countplot(x='Sex', data=train_df, palette='viridis')
plt.title('Passenger Gender Distribution (Train)')

plt.subplot(1, 2, 2)
sns.countplot(x='Embarked', data=train_df, palette='viridis')
plt.title('Port of Embarkation Distribution (Train)')

plt.show()

# Visualize the distribution of numerical variables in train dataset
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.histplot(train_df['Age'], bins=20, kde=True, color='blue')
plt.title('Age Distribution (Train)')

plt.subplot(1, 2, 2)
sns.histplot(train_df['Fare'], bins=20, kde=True, color='blue')
plt.title('Fare Distribution (Train)')

plt.show()

# Exploratory Data Analysis (EDA) for test dataset
# Summary statistics for test dataset
print("\nSummary statistics for test dataset:")
print(test_df.describe())

# Visualize the distribution of categorical variables in test dataset
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.countplot(x='Sex', data=test_df, palette='viridis')
plt.title('Passenger Gender Distribution (Test)')

plt.subplot(1, 2, 2)
sns.countplot(x='Embarked', data=test_df, palette='viridis')
plt.title('Port of Embarkation Distribution (Test)')

plt.show()

# Visualize the distribution of numerical variables in test dataset
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
sns.histplot(test_df['Age'], bins=20, kde=True, color='blue')
plt.title('Age Distribution (Test)')

plt.subplot(1, 2, 2)
sns.histplot(test_df['Fare'], bins=20, kde=True, color='blue')
plt.title('Fare Distribution (Test)')

plt.show()